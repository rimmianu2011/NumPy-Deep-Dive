{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THsE3ikMhmUQ"
      },
      "source": [
        "Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8e2llPlAhiFx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QadE19phhwQP"
      },
      "source": [
        "Section 1 — ndarray Fundamentals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sh8N_P9Qhx_N"
      },
      "source": [
        "Task 1.1: Array Creation & Shapes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fA0dNmozhpEJ"
      },
      "outputs": [],
      "source": [
        "# TODO:\n",
        "# Create a 1D array with values 0 to 99 (no loops)\n",
        "\n",
        "# HINT:\n",
        "# - Use np.arange\n",
        "\n",
        "arr_1d = np.arange(100)\n",
        "# print(arr_1d)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "llCJGu2Qh1mu"
      },
      "outputs": [],
      "source": [
        "# TODO:\n",
        "# Reshape arr_1d into a (10, 10) array\n",
        "\n",
        "# HINT:\n",
        "# - reshape does NOT copy data\n",
        "\n",
        "arr_2d = arr_1d.reshape(10, 10)\n",
        "# print(arr_2d)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2AUBC4jh32D",
        "outputId": "dbda5b12-448e-4259-f3c2-696665443a38"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4, 5, 3)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# TODO:\n",
        "# Create a 3D array of shape (4, 5, 3)\n",
        "\n",
        "# HINT:\n",
        "# - Total elements must match\n",
        "arr_3d = np.arange(4*5*3).reshape(4,5,3)\n",
        "# print(arr_3d)\n",
        "arr_3d.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cI5EhQ0IiEu8"
      },
      "source": [
        "**Explain:**\n",
        "- What does `.shape` represent?\n",
        "  - In NumPy, .shape tells you the dimensions of an array — that is, how many elements it has along each axis.\n",
        "- Why does contiguous memory matter?\n",
        "  - It matters because it allows for faster CPU access (cache friendly).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0d5b05eiJ9W"
      },
      "source": [
        "Section 1.2 — dtype & Memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cK_OEpKjh6KD",
        "outputId": "84a007e4-4a47-4707-c65f-0aff4768db7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "int64 float64\n"
          ]
        }
      ],
      "source": [
        "# TODO:\n",
        "# Create two arrays with same values but different dtypes\n",
        "\n",
        "arr = np.arange(1000)\n",
        "# arr_int = np.array([1, 2, 3, 4], dtype=np.int32)\n",
        "# arr_float = np.array([1, 2, 3, 4], dtype=np.float32)\n",
        "arr_int = arr.astype(np.int64)\n",
        "arr_float = arr.astype(np.float64)\n",
        "print(arr_int.dtype, arr_float.dtype)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J25XhniciNmu",
        "outputId": "ccd179c9-ce28-47ed-ada0-12ab0a392826"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8000 8000\n"
          ]
        }
      ],
      "source": [
        "# TODO:\n",
        "# Compare memory usage\n",
        "\n",
        "# HINT:\n",
        "# - Use .nbytes\n",
        "print(arr_int.nbytes, arr_float.nbytes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Doas6bL-iX8k"
      },
      "source": [
        "**Interview Question:**  \n",
        "Why does dtype selection matter in large ML pipelines?\n",
        "  - In big ML pipelines it matters because:\n",
        "\t- Memory: smaller dtypes use less RAM, so you can fit bigger datasets/batches/models.\n",
        "\t- Speed: smaller/optimized dtypes often run faster on GPUs.\n",
        "\t- Accuracy: too-small precision can make numbers “less exact” and hurt training.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4tHMXhCieQi"
      },
      "source": [
        "Section 2 — Indexing, Views & Copies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKv_zCtQihrL"
      },
      "source": [
        "Task 2.1: Views vs Copies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFoMJJr1iRPn",
        "outputId": "87b81a43-1121-4a23-8f8a-d3ac4d862a93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 0  1  2  3]\n",
            " [ 4  5  6  7]\n",
            " [ 8  9 10 11]\n",
            " [12 13 14 15]]\n",
            "[[ 0  1  2  3]\n",
            " [ 8  9 10 11]]\n"
          ]
        }
      ],
      "source": [
        "# TODO:\n",
        "# Create a 2D array and slice every alternate row\n",
        "\n",
        "# HINT:\n",
        "# - Use slicing, not fancy indexing\n",
        "\n",
        "A = np.arange(16).reshape(4, 4)\n",
        "A_slice = A[::2, :]\n",
        "print(A)\n",
        "print(A_slice)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZwW0qeLiYpP",
        "outputId": "54f40b78-7860-4b1e-a0d0-62c8b10f731c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-1 -1 -1 -1]\n",
            " [ 4  5  6  7]\n",
            " [-1 -1 -1 -1]\n",
            " [12 13 14 15]]\n",
            "[[-1 -1 -1 -1]\n",
            " [-1 -1 -1 -1]]\n"
          ]
        }
      ],
      "source": [
        "# TODO:\n",
        "# Modify A_slice and observe A\n",
        "A = np.arange(16).reshape(4, 4)\n",
        "# A_slice = A[::2, :].copy()\n",
        "A_slice = A[::2, :]\n",
        "A_slice[:] = -1\n",
        "\n",
        "A_slice2 = A[::2, :].copy()\n",
        "A_slice2[:] = -1\n",
        "\n",
        "print(A)\n",
        "print(A_slice2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GttQjx7ipDQ"
      },
      "source": [
        "Explain:\n",
        "- Why did the original array change (or not)?\n",
        "  - The original array changed because A_slice is a view made by slicing, so it shares the same memory as A. Modifying A_slice modifies A (for the sliced rows).\n",
        "  - A_slice2 (the one made with .copy()) is a separate copy of the data, not a view.\n",
        "\t  - A_slice2 = A[::2, :].copy() allocates new memory and duplicates those rows.\n",
        "\t  - If you modify A_slice2, A will not change, because they no longer share memory.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6W2OiBDiuaH"
      },
      "source": [
        "Section 2.2 — Boolean Masking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "WOaETRXBimsR"
      },
      "outputs": [],
      "source": [
        "# TODO:\n",
        "# Create random array of size 1000\n",
        "\n",
        "# X = np.random.rand(1000)\n",
        "# X = np.random.randint(0, 500, size=1000)\n",
        "rng = np.random.default_rng(0)\n",
        "X = rng.standard_normal(1000)\n",
        "# print(X)\n",
        "# y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "1lqB6hi1iw1N"
      },
      "outputs": [],
      "source": [
        "# TODO:\n",
        "# Extract values greater than mean\n",
        "\n",
        "# HINT:\n",
        "# - Mean first\n",
        "# - Boolean mask\n",
        "m = X.mean()\n",
        "val_grt_m = X[X>m]\n",
        "# print(val_grt_m)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhI9Mq9hiy-e",
        "outputId": "138e8a08-9bb7-4d96-a38c-e7531d163d7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean:  -0.04802827676298692\n",
            "value greater than m :  488\n",
            "negative values :  0\n"
          ]
        }
      ],
      "source": [
        "# TODO:\n",
        "# Replace negative values with 0 (no loops)\n",
        "X_copy = X.copy()\n",
        "X_copy[X_copy < 0] = 0\n",
        "\n",
        "print(\"mean: \", m)\n",
        "print(\"value greater than m : \", val_grt_m.size)\n",
        "print(\"negative values : \", (X_copy < 0).sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiPyR8Xni8M8"
      },
      "source": [
        "Section 3 — Broadcasting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZzNLC4zi-W1"
      },
      "source": [
        "Task 3.1: Broadcasting Rules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "vBzCyUtdi2AN"
      },
      "outputs": [],
      "source": [
        "# TODO:\n",
        "# Create A (1000, 50) and b (50,)\n",
        "\n",
        "# A = np.arange(1000 * 50).reshape(1000, 50)\n",
        "# b = np.arange(50,)\n",
        "\n",
        "rng = np.random.default_rng(1)\n",
        "A = rng.standard_normal((1000, 50))\n",
        "b = rng.standard_normal((50,))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "_gwUX5izjBh-"
      },
      "outputs": [],
      "source": [
        "# TODO:\n",
        "# Add b to each row of A\n",
        "\n",
        "# HINT:\n",
        "# - No reshape required\n",
        "Ab = A + b\n",
        "# print(AB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ZlPV3LMFjDf0"
      },
      "outputs": [],
      "source": [
        "# TODO:\n",
        "# Normalize each row of A\n",
        "\n",
        "# HINT:\n",
        "# - Axis matters\n",
        "# - Keep dimensions in mind\n",
        "# A_norm = A / A.sum(axis=1, keepdims=True)\n",
        "row_mean = A.mean(axis=1, keepdims=True)\n",
        "row_std = A.std(axis=1, keepdims=True)\n",
        "A_norm = (A - row_mean) / row_std\n",
        "# print(A_norm)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "damGC04kjJ4C"
      },
      "source": [
        "Explain broadcasting step-by-step.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZJZS8x6jMSa"
      },
      "source": [
        "Section 3.2 — Broadcasting Trap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBChDtpejHN6",
        "outputId": "0f9f2f85-1ee3-4e1d-bd4f-5d914c56f365"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Expected broadcasting error:  operands could not be broadcast together with shapes (1000,50) (1000,) \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(1000, 50)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# TODO:\n",
        "# Intentionally trigger a broadcasting error\n",
        "# Then fix it\n",
        "col = np.arange(1000)\n",
        "try:\n",
        "  _ = A - col\n",
        "except ValueError as e:\n",
        "  print(\"Expected broadcasting error: \", e)\n",
        "\n",
        "col2 = col.reshape(-1, 1)\n",
        "A_modified = A - col2\n",
        "A_modified.shape\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87Hg6pHcjUz_"
      },
      "source": [
        "What was wrong with the original shapes?\n",
        "  - The shapes of the two array did not match; one was (1000, 50) amd the other was (1000,).\n",
        "  - After modifying the array and setting (1000,) -> (1000, 1) the broadcasting step was executed.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lJkIZKwjbic"
      },
      "source": [
        "Section 4 — Vectorization vs Loops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-ku-91djdb5"
      },
      "source": [
        "Task 4.1: Loop vs Vectorized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "9HEd9iD7jRkx"
      },
      "outputs": [],
      "source": [
        "# TODO:\n",
        "# Create large array X of size 1,000,000\n",
        "\n",
        "rng = np.random.default_rng(2)\n",
        "X = rng.standard_normal(1_000_000)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mwCsbQIjb6C",
        "outputId": "7ccc5ba3-4410-4bc3-f53c-4bde7e575a87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7518\n"
          ]
        }
      ],
      "source": [
        "# TODO:\n",
        "# Normalize using Python loop\n",
        "\n",
        "# HINT:\n",
        "# - Time it\n",
        "\n",
        "X_mean = X.mean()\n",
        "sigma = X.std()\n",
        "t0 = time.time()\n",
        "out_loop = np.empty_like(X)\n",
        "for i in range(X.shape[0]):\n",
        "  out_loop[i] = (X[i] - X_mean) / sigma\n",
        "total_time = time.time() - t0\n",
        "print(round(total_time, 4))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnBPlOLPjjEQ",
        "outputId": "7f08eabc-640f-4024-e776-b59abf147caa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "71.2\n",
            "allclose :  True\n"
          ]
        }
      ],
      "source": [
        "# TODO:\n",
        "# Normalize using vectorization\n",
        "t1 = time.time()\n",
        "out_vec = (X - X_mean) / sigma\n",
        "vec_time = time.time() - t1\n",
        "round(vec_time, 4)\n",
        "print(round(total_time/max(vec_time, 1e-12), 1))\n",
        "print('allclose : ', np.allclose(out_loop, out_vec))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4JkKYiujqns"
      },
      "source": [
        "Why is vectorization faster?\n",
        "- Runs computations in optimized C code instead of Python loops\n",
        "- Avoids Python interpreter overhead per iteration\n",
        "- Uses CPU optimizations (SIMD, cache efficiency)\n",
        "- Processes many elements in one operation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVuPkVV8jtLF"
      },
      "source": [
        "Task 4.2: Pairwise Distance (FAANG Classic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XISh6eh3joJ7",
        "outputId": "9d730373-70dc-49a6-f949-3b876463e3d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(200, 200)\n",
            "diag ~ 0 :  True\n",
            "symmetric :  True\n"
          ]
        }
      ],
      "source": [
        "# TODO:\n",
        "# Compute pairwise Euclidean distance matrix without loops\n",
        "\n",
        "# HINT:\n",
        "# - Use (x - y)^2 expansion\n",
        "# - Broadcasting is key\n",
        "\n",
        "def pairwise_distance(X):\n",
        "    ...\n",
        "    sq_dist = np.sum(X * X, axis = 1, keepdims=True)\n",
        "    total_dist = sq_dist + sq_dist.T - 2 * (X @ X.T)\n",
        "    total_dist = np.maximum(total_dist, 0.0)\n",
        "    return np.sqrt(total_dist)\n",
        "\n",
        "X = np.random.default_rng(3)\n",
        "Y = X.standard_normal((200, 10))\n",
        "Distance = pairwise_distance(Y)\n",
        "print(Distance.shape)\n",
        "# print(Distance)\n",
        "print('diag ~ 0 : ', np.allclose(np.diag(Distance), 0, atol = 1e-7))\n",
        "print('symmetric : ', np.allclose(Distance, Distance.T, atol = 1e-7))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7rZh53cjy9I"
      },
      "source": [
        "Section 5 — Numerical Stability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQLltnsQjzs-"
      },
      "source": [
        "Task 5.1: Softmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thv3qP03jwbC",
        "outputId": "881179dc-e686-436a-dce7-2036113b0c89"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2473912254.py:5: RuntimeWarning: overflow encountered in exp\n",
            "  exp_val = np.exp(X)\n",
            "/tmp/ipython-input-2473912254.py:6: RuntimeWarning: invalid value encountered in divide\n",
            "  return exp_val/exp_val.sum(axis=1, keepdims=True)\n"
          ]
        }
      ],
      "source": [
        "# TODO:\n",
        "# Implement naive softmax\n",
        "\n",
        "def softmax_naive(X):\n",
        "  exp_val = np.exp(X)\n",
        "  return exp_val/exp_val.sum(axis=1, keepdims=True)\n",
        "\n",
        "\n",
        "X = np.array([[1000.0, 1001.0, 1002.0]])\n",
        "try:\n",
        "  softmax_naive(X)\n",
        "except FloatingPointError as e:\n",
        "  print('overflow : ', e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9JGLgIOj6K2",
        "outputId": "eb2c5352-2a6d-425d-feb4-77d62dcfb11a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stable :  [[0.09003057 0.24472847 0.66524096]]\n",
            "Stable :  [1.]\n"
          ]
        }
      ],
      "source": [
        "from enum import KEEP\n",
        "from contextlib import AsyncExitStack\n",
        "# TODO:\n",
        "# Fix numerical instability\n",
        "\n",
        "# HINT:\n",
        "# - Subtract max per row\n",
        "\n",
        "def softmax_stable(X):\n",
        "  new_X = X - X.max(axis=1, keepdims=True)\n",
        "  # print(new_X)\n",
        "  exp_val2 = np.exp(new_X)\n",
        "  return exp_val2/exp_val2.sum(axis = 1, keepdims=True)\n",
        "\n",
        "print('Stable : ', softmax_stable(X))\n",
        "print('Stable : ', softmax_stable(X).sum(axis = 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlzVyosFkCwi"
      },
      "source": [
        "Why does subtracting max work?\n",
        "- Subtracting the max works because softmax is shift-invariant.\n",
        "- So subtracting any constant c (for instance, the row-wise max) does not change the output.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hR3jiBxbkFSb"
      },
      "source": [
        "Section 6 — Linear Algebra"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rg9_HtukkHCg"
      },
      "source": [
        "Task 6.1: Matrix Multiplication"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpheXo3gkAuU",
        "outputId": "4f9cd682-8e44-4b13-927c-1318d34b4635"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-2.49757386  2.98319337  2.52249303  5.85602501 -4.09211309]\n",
            " [-0.7017924  -2.52493983 -1.68029009 -0.90642378  3.91117743]]\n",
            "(2, 5)\n",
            "Invalid matrix multiplication :  matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 2 is different from 4)\n",
            "A @ B == dot.product => True\n",
            "A @ B == matmul =>  True\n"
          ]
        }
      ],
      "source": [
        "# TODO:\n",
        "# Try valid and invalid matrix multiplications\n",
        "A = np.random.default_rng(3).standard_normal((2,4))\n",
        "B = np.random.default_rng(4).standard_normal((4, 5))\n",
        "matrix_result = A @ B\n",
        "print(matrix_result)\n",
        "print(matrix_result.shape)\n",
        "\n",
        "try:\n",
        "  _ = A @ A\n",
        "except ValueError as e:\n",
        "  print('Invalid matrix multiplication : ', e)\n",
        "print('A @ B == dot.product =>', np.allclose(np.dot(A, B), matrix_result))\n",
        "print('A @ B == matmul => ', np.allclose(np.matmul(A, B), matrix_result))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVfOrat1kMr8"
      },
      "source": [
        "Explain difference between dot, @, and matmul.\n",
        "\n",
        "  - @ and np.matmul(): basically the same thing (matrix multiplication). a @ b == np.matmul(a, b).\n",
        "  - np.dot(): older, more “general” rule:\n",
        "\t  - 1D·1D -> scalar dot product (same result as @)\n",
        "\t  - 2D·2D -> matrix multiply (same as @)\n",
        "    - Greater than 2D -> uses different axis rules than matmul (can give different shapes/results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HU3JZWorkPpg"
      },
      "source": [
        "Task 6.2: Solving Linear Systems"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnQSyMMAkJjP",
        "outputId": "2b56a9ac-7582-483e-fe17-40c756a11211"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-3.36038187  0.99835524  0.56598579  7.10732223  2.42696993]\n",
            "residual :  1.7702748954631059e-15\n"
          ]
        }
      ],
      "source": [
        "# TODO:\n",
        "# Solve Ax = b and verify solution\n",
        "rng = np.random.default_rng(6)\n",
        "A = rng.standard_normal((5, 5))\n",
        "b = rng.standard_normal((5, ))\n",
        "X = np.linalg.solve(A, b)\n",
        "resid = np.linalg.norm(A @ X - b)\n",
        "print(X)\n",
        "print('residual : ',resid)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QeS-ldakXCR"
      },
      "source": [
        "Section 7 — Performance & Memory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4x_u1MHTkSiM"
      },
      "source": [
        "Task 7.1: In-Place Operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBjd0sjkkR-J",
        "outputId": "7136fac5-a26b-4f7a-f0cd-21b80b0354ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.016837120056152344\n",
            "0.0040743350982666016\n"
          ]
        }
      ],
      "source": [
        "# TODO:\n",
        "# Compare in-place vs out-of-place operations\n",
        "X = np.random.default_rng(8).standard_normal(2_000_000)\n",
        "Y = X.copy()\n",
        "t0 = time.time()\n",
        "Z = X + 1.0\n",
        "out_time = time.time() - t0\n",
        "\n",
        "t1 = time.time()\n",
        "Y += 1.0\n",
        "out_time2 = time.time() - t1\n",
        "\n",
        "print(out_time)\n",
        "print(out_time2)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4w93mTd4kfsa"
      },
      "source": [
        "Task 7.2: Strides"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OYTZ5WYkcNM",
        "outputId": "5a83970f-7236-44da-a0c1-427c2e16730c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A shape : (6, 4) -----  A stride :  (32, 8)\n",
            "B shape : (6, 2) -----  B stride :  (32, 16)\n"
          ]
        }
      ],
      "source": [
        "# TODO:\n",
        "# Inspect array strides and explain\n",
        "A = np.arange(24).reshape(6, 4)\n",
        "B = A[:, ::2]\n",
        "\n",
        "print('A shape :', A.shape, '-----  A stride : ', A.strides)\n",
        "print('B shape :', B.shape, '-----  B stride : ', B.strides)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJS6dnBXkrMn"
      },
      "source": [
        "Section 8 — Mini Case Study"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZm_yBGrkjDG",
        "outputId": "23cd373f-f5bd-4eb1-abc0-5c679403db4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 10 elements :  [99 98 97 96 95 94 93 92 91 90]\n"
          ]
        }
      ],
      "source": [
        "# TODO:\n",
        "# Given X (10000, 100):\n",
        "rng = np.random.default_rng(8)\n",
        "X = rng.standard_normal((10_000, 100))\n",
        "\n",
        "# - Normalize features\n",
        "X_mean = X.mean(axis = 0, keepdims=True)\n",
        "X_std = X.std(axis=0, keepdims=True)\n",
        "Xn = (X - X_mean)/ X_std\n",
        "# print(Xn)\n",
        "\n",
        "# - Compute covariance\n",
        "Covariance = (Xn.T @ Xn) / (Xn.shape[0] - 1)\n",
        "\n",
        "# - Extract top-k eigenvectors\n",
        "eigen_val, eigen_vec = np.linalg.eigh(Covariance)\n",
        "# print(eigen_vec.shape)\n",
        "# print(eigen_val.shape)\n",
        "k = 10\n",
        "top_val = np.argsort(eigen_val)[-k:][::-1]\n",
        "print('Top 10 elements : ', top_val)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDa-rOw7kxZi"
      },
      "source": [
        "Explain each step and its ML relevance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILzCnvoMk0S0"
      },
      "source": [
        "1. Where did NumPy save memory?\n",
        "  - By using contiguous arrays and views\n",
        "2. Where did it avoid Python overhead?\n",
        "  - In vectorized ops: mean, std, @ (matmul), and np.linalg.eigh — all run in compiled C, not in python loop.\n",
        "3. Which operation would break at scale?\n",
        "  - Eigen-decomposition (np.linalg.eigh): infeasible for very large feature dimensions.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
